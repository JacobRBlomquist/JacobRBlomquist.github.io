<!DOCTYPE html>
<html>
<head>


    <base target="_blank">

    <title>gUM audio</title>
<link rel="stylesheet" href="../dfma/main.css">

</head>

<body>

<ul id="nav">
        <li><a href="https://blomquist.xyz" target=_blank>Home</a></li>
 </ul>
	
<div id="container">

    <h1>getUserMedia, audio only</span>
    </h1>

<!--     <audio id="gum-local" controls autoplay></audio> -->

    <p class="warning">Warning: if you're not using headphones,this page will cause feedback.</p>

<!--     <p>Render the audio stream from an audio-only <code>getUserMedia()</code> call with an audio element.</p>

    <p>The <code>MediaStream</code> object <code><em>stream</em></code> passed to the <code>getUserMedia()</code>
        callback is in global scope, so you can inspect it from the console.</p>
    <div> -->
        <span id="errorMsg"></span>
    </div>


</div>




    <script>

'use strict';

// Put variables in global scope to make them available to the browser console.
const audio = document.querySelector('audio');

const constraints = window.constraints = {
  audio:  {
	latency: 0.00,
        autoGainControl: false,
        echoCancellation: {exact: false},
	sampleSize: 10,
	mozAutoGainControl:false,
	mozNoiseSuppression: false,
	
        advanced: [{
            echoCancellation: {exact: false}
          }, 
          {googEchoCancellation: {exact: false}}, 
          {googExperimentalEchoCancellation: {exact: false}}, 
          {googDAEchoCancellation: {exact: false}}, 
          {googAutoGainControl: {exact: false}}, 
          {googExperimentalAutoGainControl: {exact: false}}, 
          {googNoiseSuppression: {exact: false}}, 
          {googExperimentalNoiseSuppression: {exact: false}}, 
          {googHighpassFilter: {exact: false}}, 
          {googTypingNoiseDetection: {exact: false}}, 
          {googAudioMirroring: {exact: false}}, 
          {googNoiseReduction: {exact: false}},
	  {mozNoiseSuppression:{exact: false}},
  	  {mozAutoGainControl: {exact: false}}
        ]  
      },
  video: false
};

function handleSuccess(stream) {
  /*const audioTracks = stream.getAudioTracks();
 /* console.log('Got stream with constraints:', constraints);
  console.log('Using audio device: ' + audioTracks[0].label);
  stream.oninactive = function() {
    console.log('Stream ended');
  };
  window.stream = stream; // make variable available to browser console
  audio.srcObject = stream;*/
//https://developers.google.com/web/updates/2012/09/Live-Web-Audio-Input-Enabled

	window.AudioContext = window.AudioContext || window.webkitAudioContext;
	let audioContext = new AudioContext();
	let mediaStreamSource = audioContext.createMediaStreamSource(stream)
	mediaStreamSource.connect(audioContext.destination);

}

function handleError(error) {
  const errorMessage = 'navigator.MediaDevices.getUserMedia error: ' + error.message + ' ' + error.name;
  document.getElementById('errorMsg').innerText = errorMessage;
  console.log(errorMessage);
}

navigator.mediaDevices.getUserMedia(constraints).then(handleSuccess).catch(handleError);


	</script>


</body>
</html>




<!-- <!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Document</title>
  <script>

navigator.getUserMedia = navigator.getUserMedia || 
					 navigator.webkitGetUserMedia ||
					 navigator.mozGetUserMedia ||
					 navigator.msGetUserMedia;

	let done = false;
	let leftChannel = [];
	let grecorder;
	let recordingLength = 0;
	let PCM32fSamples;
	let sampleRate ;
	let audioContext;

	function successfullyGotInput(stream){
		if(!stream){
			alert("Invalid stream")
			return;		
		}

		const context = window.AudioContext || window.webkitAudioContext;
		audioContext = new context();
		
		sampleRate = audioContext.sampleRate;
		const volume = audioContext.createGain();

		const audioInput = audioContext.createMediaStreamSource(stream);
		audioInput.connect(volume);

		const bufferSize = 2048;
		const recorder = (audioContext.createScriptProcessor || audioContext.createJavaScriptNode).call(audioContext,
													 	bufferSize,
													 	1,
						   							 	1);
		grecorder = recorder;		

		recorder.onaudioprocess = function(event){
			const samples = event.inputBuffer.getChannelData(0);

			leftChannel.push(new Float32Array(samples));
			recordingLength+=bufferSize;
		};

		volume.connect(recorder);
		recorder.connect(audioContext.destination);
		setStatus("Recording...");

		

	}

	function setStatus(msg){
		document.querySelector("#status").textContent=msg;
	}

	function start(){
		leftChannel = [];
		recordingLength = 0;

		document.querySelector("#start").disabled = true;
		document.querySelector("#stop").disabled=false;
		document.querySelector("#play").disabled=true;

		if(grecorder){
			grecorder.connect(audioContext.destination);
			setStatus("Recording...");
			return;
		}
		if(navigator.getUserMedia)
		{
			navigator.getUserMedia({audio:true},
			successfullyGotInput
			, function(error){
				setStatus("Error capturing audio: "+error)
			});
		} else {
			setStatus("getUserMedia is not supported on this browser\nThis only works when using HTTPS, if you get an error, try typing \"https://\" in front of the URL in the address bar.");
			return;
		}

	
        }
	function play(){
		if(!done){
			alert("Recording not complete");
			return;
		}

		console.log(PCM32fSamples);
		
	
		let audioCtx = new (window.AudioContext || window.webkitAudioContext)();
		let channels = 1;
		
		let frameCount = PCM32fSamples.length;
		let audioBuffer = audioCtx.createBuffer(channels,frameCount,sampleRate);
		
		let nowBuffering = audioBuffer.getChannelData(0,32,sampleRate);
		for(let i = 0;i<frameCount;i++)
		{
			nowBuffering[i]  = PCM32fSamples[i];
		}

		let source = audioCtx.createBufferSource();
		source.buffer = audioBuffer;
		source.connect(audioCtx.destination);
		source.start();

        }
	function stop(){
		if(!grecorder)
			return;
		grecorder.disconnect();
		//merge buffers
		PCM32fSamples = new Float32Array(recordingLength);
		let offset = 0;

		for(let i = 0;i<leftChannel.length;i++)
		{
			PCM32fSamples.set(leftChannel[i],offset);
			offset+=leftChannel[i].length;
		}
		done=true;

		let duration = recordingLength / sampleRate;

		let spn = document.querySelector("#status");
		setStatus("Recorded Duration: "+duration.toFixed(3)+"s.");

		document.querySelector("#start").disabled = false;
		document.querySelector("#stop").disabled=true;
		document.querySelector("#play").disabled=false;

        }
  </script>
</head>
<body>
  <h1>Record and playback audio in browser.</h1>
  <div>
    <button onclick="start()" id="start">Start</button>
    <button onclick="stop()" id="stop" disabled>Stop</button>
    <button onclick="play()" id="play" disabled>Play</button>
  </div>
  <div>
    <span id=status></span>
  </div>
	
</body>
</html>
 -->
